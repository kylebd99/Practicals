{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import numpy\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test.csv\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainVals = train.values\n",
    "testVals = test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = testVals\n",
    "X_test = np.delete(X_test,0,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = trainVals[:,len(trainVals[0])-1]\n",
    "X_train = trainVals\n",
    "X_train=np.delete(X_train, 88200, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainFFT = np.zeros(X_train.shape)\n",
    "print(len(X_train))\n",
    "for i in range(len(X_train)):\n",
    "    trainFFT[i] = np.fft.fft(X_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting mfcc means\n",
    "trainMFCCs = np.zeros((X_train.shape[0],173,10))\n",
    "for i in range(len(X_train)):\n",
    "    trainMFCCs[i] = librosa.feature.melspectrogram(y=X_train[i],sr = 44100,n_mels=10,hop_length = 512).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88200"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainMFCCs.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "bagging = BaggingClassifier(SVC(C=1,gamma = .5),\n",
    "                            max_samples=.75, max_features=.75, n_estimators=50)\n",
    "bagging.fit(trainMFCCs,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(Y_train,bagging.predict(trainMFCCs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "testMFCCs = np.zeros((X_test.shape[0],173,10))\n",
    "for i in range(len(X_test)):\n",
    "    testMFCCs[i] = librosa.feature.melspectrogram(y=X_test[i],sr = 44100,n_mels=10,hop_length=512).T\n",
    "testFlat = []\n",
    "for i in range(testMFCCs.shape[0]):\n",
    "    temp = []\n",
    "    for x in range(testMFCCs.shape[1]):\n",
    "        for z in range(testMFCCs.shape[2]):\n",
    "            temp.append(testMFCCs[i][x][z])\n",
    "    testFlat.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainMFCCs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6325, 690, 40)\n",
      "27600\n"
     ]
    }
   ],
   "source": [
    "flatTrain = []\n",
    "for i in range(trainMFCCs.shape[0]):\n",
    "    temp = []\n",
    "    for x in range(trainMFCCs.shape[1]):\n",
    "        for z in range(trainMFCCs.shape[2]):\n",
    "            temp.append(trainMFCCs[i][x][z])\n",
    "    flatTrain.append(temp)\n",
    "print(trainMFCCs.shape)\n",
    "print(len(flatTrain[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6125 samples, validate on 200 samples\n",
      "Epoch 1/15\n",
      "6125/6125 [==============================] - 100s 16ms/step - loss: 3.0690 - acc: 0.5838 - val_loss: 2.3898 - val_acc: 0.6700\n",
      "Epoch 2/15\n",
      "6125/6125 [==============================] - 99s 16ms/step - loss: 2.0063 - acc: 0.6731 - val_loss: 3.4468 - val_acc: 0.5400\n",
      "Epoch 3/15\n",
      "6125/6125 [==============================] - 116s 19ms/step - loss: 1.5570 - acc: 0.7409 - val_loss: 2.2065 - val_acc: 0.6950\n",
      "Epoch 4/15\n",
      "6125/6125 [==============================] - 119s 19ms/step - loss: 1.0159 - acc: 0.8300 - val_loss: 1.3588 - val_acc: 0.8350\n",
      "Epoch 5/15\n",
      "6125/6125 [==============================] - 118s 19ms/step - loss: 0.8864 - acc: 0.8444 - val_loss: 1.1480 - val_acc: 0.8050\n",
      "Epoch 6/15\n",
      "6125/6125 [==============================] - 117s 19ms/step - loss: 0.8212 - acc: 0.8684 - val_loss: 1.1075 - val_acc: 0.8400\n",
      "Epoch 7/15\n",
      "6125/6125 [==============================] - 118s 19ms/step - loss: 0.6667 - acc: 0.8877 - val_loss: 1.4013 - val_acc: 0.7800\n",
      "Epoch 8/15\n",
      "6125/6125 [==============================] - 119s 19ms/step - loss: 0.6934 - acc: 0.8999 - val_loss: 1.1155 - val_acc: 0.8550\n",
      "Epoch 9/15\n",
      "6125/6125 [==============================] - 123s 20ms/step - loss: 1.5730 - acc: 0.8173 - val_loss: 1.2307 - val_acc: 0.8250\n",
      "Epoch 10/15\n",
      "6125/6125 [==============================] - 123s 20ms/step - loss: 0.6332 - acc: 0.8927 - val_loss: 1.4083 - val_acc: 0.8250\n",
      "Epoch 11/15\n",
      "6125/6125 [==============================] - 120s 20ms/step - loss: 1.4172 - acc: 0.8472 - val_loss: 1.2203 - val_acc: 0.8350\n",
      "Epoch 12/15\n",
      "6125/6125 [==============================] - 123s 20ms/step - loss: 0.4893 - acc: 0.9290 - val_loss: 1.0525 - val_acc: 0.8850\n",
      "Epoch 13/15\n",
      "6125/6125 [==============================] - 124s 20ms/step - loss: 0.3516 - acc: 0.9536 - val_loss: 1.1163 - val_acc: 0.8550\n",
      "Epoch 14/15\n",
      "6125/6125 [==============================] - 121s 20ms/step - loss: 0.3993 - acc: 0.9479 - val_loss: 1.0672 - val_acc: 0.8900\n",
      "Epoch 15/15\n",
      "6125/6125 [==============================] - 118s 19ms/step - loss: 0.4581 - acc: 0.9437 - val_loss: 1.0958 - val_acc: 0.8900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ee39e82e8>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yval = Y_train[:200]\n",
    "flatTrain = np.array(flatTrain)\n",
    "Xval = flatTrain[:200]\n",
    "model = Sequential()\n",
    "model.add(Dense(2056, input_shape=(len(flatTrain[1]),), activation = 'relu'))\n",
    "#model.add(Dropout(0.1))\n",
    "model.add(Dense(2056, activation='relu'))\n",
    "#model.add(Dropout(0.1))\n",
    "model.add(Dense(2056, activation='relu'))\n",
    "#model.add(Dropout(0.1))\n",
    "model.add(Dense(2056, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "model.fit(flatTrain[200:],Y_train[200:],epochs = 15,batch_size=32,validation_data = (Xval,Yval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6125 samples, validate on 200 samples\n",
      "Epoch 1/5\n",
      "6125/6125 [==============================] - 57s 9ms/step - loss: 0.8743 - acc: 0.9154 - val_loss: 0.1770 - val_acc: 1.0000\n",
      "Epoch 2/5\n",
      "6125/6125 [==============================] - 56s 9ms/step - loss: 0.1021 - acc: 0.9962 - val_loss: 0.0610 - val_acc: 1.0000\n",
      "Epoch 3/5\n",
      "6125/6125 [==============================] - 55s 9ms/step - loss: 0.0425 - acc: 0.9989 - val_loss: 0.0325 - val_acc: 1.0000\n",
      "Epoch 4/5\n",
      "6125/6125 [==============================] - 55s 9ms/step - loss: 0.0236 - acc: 0.9998 - val_loss: 0.0212 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "6125/6125 [==============================] - 55s 9ms/step - loss: 0.0159 - acc: 0.9998 - val_loss: 0.0155 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c3b6ad710>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''X_trainLSTM = np.zeros((X_train.shape[0],X_train.shape[1],1))\n",
    "for i in range(X_train.shape[0]):\n",
    "    for x in range(X_train.shape[1]):\n",
    "        X_trainLSTM[i][x][0] = X_train[i][x]'''\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(X_train.shape[1],), activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256))\n",
    "#model.add(LSTM(1,input_shape=(X_trainLSTM.shape[1],X_trainLSTM.shape[2])))\n",
    "#model.add(LSTM(256, input_shape=(trainMFCCs.shape[1],trainMFCCs.shape[2])))\n",
    "#model.add(LSTM(256))\n",
    "#model.add(Dense(units=512))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "model.fit(X_train[200:],Y_train[200:],epochs = 5,batch_size=32,validation_data = (X_train[:200],Y_train[:200]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1 = model.predict(X_test)\n",
    "preds = [np.argmax(i) for i in preds1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file(filename, predictions):\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(\"Id,Prediction\\n\")\n",
    "        for i,p in enumerate(predictions):\n",
    "            f.write(str(i) + \",\" + str(p) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_file(\"predictionsRawDense256Dropout02Dense256.csv\",preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
